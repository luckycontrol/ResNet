{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/torch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels: int, out_channels: int, stride: int = 1, groups: int = 1, dilation: int = 1):\n",
    "    # BatchNorm에 bias가 있으므로 bias는 False\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_channels: int, out_channels: int, stride: int = 1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(pl.LightningModule):\n",
    "    def __init__(self, in_channels: int = 3, out_channels: int = 3, stride: int = 1, downsample =  None, groups: int = 1, base_width: int = 64, dilation: int = 1, norm_layer = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = norm_layer(out_channels)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = norm_layer(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            res = self.downsample(res)\n",
    "\n",
    "        x += res\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(pl.LightningModule):\n",
    "\n",
    "    expansion = 4 # 3번째 conv layer에서 차원을 증가시키기 위한 확장계수\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int, downsample = None, groups: int = 1, base_width: int = 64, dilation: int = 1, norm_layer = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if norm_layer is not None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        width = int(out_channels * (base_width / 64.)) * groups\n",
    "        \n",
    "        self.conv1 = conv1x1(in_channels, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        # Kaming He에 따르면 stride를 어디에 배치하든 연산의 차이는 크게 없다. 즉 의미는 없다.\n",
    "        # 요지는 conv1x1 -> conv3x3 -> conv1x1에 따른 연산량 조절이 핵심.\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, out_channels * self.expansion)\n",
    "        self.bn3 = norm_layer(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "\n",
    "        # 1x1 conv layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # 3x3 conv layer\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        # 1x1 conv layer\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        # skip connection\n",
    "        if self.downsample is not None:\n",
    "            res = self.downsample(res)\n",
    "        \n",
    "        x += res\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "    block, \n",
    "    layers, \n",
    "    num_classes = 1000, \n",
    "    zero_init_residual=False, \n",
    "    groups=1, \n",
    "    width_per_group=64, \n",
    "    replace_stride_width_dilation=None,\n",
    "    norm_layer=None\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if norm_layer is not None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.norm_layer = norm_layer\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 3, 224, 224]              81\n",
      "       BatchNorm2d-2          [-1, 3, 224, 224]               6\n",
      "            Conv2d-3          [-1, 3, 224, 224]              81\n",
      "       BatchNorm2d-4          [-1, 3, 224, 224]               6\n",
      "================================================================\n",
      "Total params: 174\n",
      "Trainable params: 174\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 4.59\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 5.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(BasicBlock(), (3, 224, 224), device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04c55434ed2b08bb5bf53ae5f55862aa0e3be3e7e24f24482bddca5922bab6dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
